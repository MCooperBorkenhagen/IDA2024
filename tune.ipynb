{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from src.learner import *\n",
    "import time\n",
    "from utilities import remove_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tuning for the `kidwords` set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs and outputs\n",
    "X = remove_cols(np.genfromtxt('data/orth-kid.csv', delimiter=\",\"))\n",
    "Y = remove_cols(np.genfromtxt('data/phon-kid.csv', delimiter=\",\"))\n",
    "words = pd.read_csv('data/kidwords.csv', header=None)[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limited search across HPs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 12:08:20.048867: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "seed = 387\n",
    "with open('outputs/tune/tune.csv', 'w') as f:\n",
    "    f.write(\"{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                            \"hidden_units\",\n",
    "                                            \"learning_rate\",\n",
    "                                             \"batch_size\",\n",
    "                                             \"epochs\",\n",
    "                                             \"loss_train\",\n",
    "                                             \"accuracy_train\",\n",
    "                                             \"mse_train\",\n",
    "                                             \"loss_test\",\n",
    "                                             \"accuracy_test\",\n",
    "                                             \"mse_test\",\n",
    "                                             \"time\"))\n",
    "    for learning_rate in [.01, .025, .05, .075, .1, .15, .2, .25, None]: \n",
    "        for batch_size in [16, 32, 64, 96, 128, 256]:\n",
    "            for epochs in [50, 100, 150, 200, 250, 300]:\n",
    "                for hidden in [80, 100, 120]:\n",
    "\n",
    "                    if learning_rate is not None:\n",
    "                        optimizer = Adam(learning_rate=learning_rate)\n",
    "                    if learning_rate is None:\n",
    "                        optimzer = None\n",
    "\n",
    "                    model = learner(X, Y, seed, hidden, optimizer=None)\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "\n",
    "\n",
    "                    model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=False)\n",
    "\n",
    "                    end_time = time.time()\n",
    "                    runtime = end_time - start_time\n",
    "\n",
    "                    loss_train, accuracy_train, mse_train = model.evaluate(X, Y, verbose=0) \n",
    "                    loss_test, accuracy_test, mse_test = model.evaluate(X, Y, verbose=0) \n",
    "\n",
    "                    f.write(\"{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    hidden,\n",
    "                                                    learning_rate,\n",
    "                                                    batch_size,\n",
    "                                                    epochs,\n",
    "                                                    loss_train,\n",
    "                                                    accuracy_train,\n",
    "                                                    mse_train,\n",
    "                                                    loss_test,\n",
    "                                                    accuracy_test,\n",
    "                                                    mse_test,\n",
    "                                                    runtime))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune without removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 387\n",
    "\n",
    "X = np.genfromtxt('data/orth-kid.csv', delimiter=\",\")\n",
    "Y = np.genfromtxt('data/phon-kid.csv', delimiter=\",\")\n",
    "\n",
    "with open('outputs/tune/tune_2.csv', 'w') as f:\n",
    "    f.write(\"{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                            \"hidden_units\",\n",
    "                                            \"learning_rate\",\n",
    "                                             \"batch_size\",\n",
    "                                             \"epochs\",\n",
    "                                             \"loss_train\",\n",
    "                                             \"accuracy_train\",\n",
    "                                             \"mse_train\",\n",
    "                                             \"loss_test\",\n",
    "                                             \"accuracy_test\",\n",
    "                                             \"mse_test\",\n",
    "                                             \"time\"))\n",
    "    for learning_rate in [.01, .025, .05, .075, .1, .15, .2, .25, None]: \n",
    "        for batch_size in [16, 32, 64, 96, 128, 256]:\n",
    "            for epochs in [50, 100, 150, 200, 250, 300]:\n",
    "                for hidden in [80, 100, 120]:\n",
    "\n",
    "                    if learning_rate is not None:\n",
    "                        optimizer = Adam(learning_rate=learning_rate)\n",
    "                    if learning_rate is None:\n",
    "                        optimzer = None\n",
    "\n",
    "                    model = learner(X, Y, seed, hidden, optimizer=None)\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "\n",
    "\n",
    "                    model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=False)\n",
    "\n",
    "                    end_time = time.time()\n",
    "                    runtime = end_time - start_time\n",
    "\n",
    "                    loss_train, accuracy_train, mse_train = model.evaluate(X, Y, verbose=0) \n",
    "                    loss_test, accuracy_test, mse_test = model.evaluate(X, Y, verbose=0) \n",
    "\n",
    "                    f.write(\"{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    hidden,\n",
    "                                                    learning_rate,\n",
    "                                                    batch_size,\n",
    "                                                    epochs,\n",
    "                                                    loss_train,\n",
    "                                                    accuracy_train,\n",
    "                                                    mse_train,\n",
    "                                                    loss_test,\n",
    "                                                    accuracy_test,\n",
    "                                                    mse_test,\n",
    "                                                    runtime))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjustable learning rate (without removing columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 16 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 32 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 64 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 96 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 128 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.01 batch_size: 256 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 16 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 32 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 64 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 96 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 128 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.025 batch_size: 256 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 16 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 32 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 64 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 96 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 128 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.05 batch_size: 256 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 16 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 32 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 64 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 96 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 128 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.075 batch_size: 256 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 16 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 32 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 64 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 96 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 128 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.1 batch_size: 256 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 16 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 32 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 64 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 96 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 128 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.15 batch_size: 256 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 16 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 32 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 64 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 96 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 128 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.2 batch_size: 256 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 16 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 32 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 64 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 96 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 128 epochs: 300 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 50 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 50 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 50 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 100 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 100 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 100 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 150 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 150 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 150 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 200 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 200 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 200 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 250 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 250 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 250 hidden: 120\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 300 hidden: 80\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 300 hidden: 100\n",
      "Working on: learning rate: 0.25 batch_size: 256 epochs: 300 hidden: 120\n",
      "Working on: learning rate: None batch_size: 16 epochs: 50 hidden: 80\n",
      "Working on: learning rate: None batch_size: 16 epochs: 50 hidden: 100\n",
      "Working on: learning rate: None batch_size: 16 epochs: 50 hidden: 120\n",
      "Working on: learning rate: None batch_size: 16 epochs: 100 hidden: 80\n",
      "Working on: learning rate: None batch_size: 16 epochs: 100 hidden: 100\n",
      "Working on: learning rate: None batch_size: 16 epochs: 100 hidden: 120\n",
      "Working on: learning rate: None batch_size: 16 epochs: 150 hidden: 80\n",
      "Working on: learning rate: None batch_size: 16 epochs: 150 hidden: 100\n",
      "Working on: learning rate: None batch_size: 16 epochs: 150 hidden: 120\n",
      "Working on: learning rate: None batch_size: 16 epochs: 200 hidden: 80\n",
      "Working on: learning rate: None batch_size: 16 epochs: 200 hidden: 100\n",
      "Working on: learning rate: None batch_size: 16 epochs: 200 hidden: 120\n",
      "Working on: learning rate: None batch_size: 16 epochs: 250 hidden: 80\n",
      "Working on: learning rate: None batch_size: 16 epochs: 250 hidden: 100\n",
      "Working on: learning rate: None batch_size: 16 epochs: 250 hidden: 120\n",
      "Working on: learning rate: None batch_size: 16 epochs: 300 hidden: 80\n",
      "Working on: learning rate: None batch_size: 16 epochs: 300 hidden: 100\n",
      "Working on: learning rate: None batch_size: 16 epochs: 300 hidden: 120\n",
      "Working on: learning rate: None batch_size: 32 epochs: 50 hidden: 80\n",
      "Working on: learning rate: None batch_size: 32 epochs: 50 hidden: 100\n",
      "Working on: learning rate: None batch_size: 32 epochs: 50 hidden: 120\n",
      "Working on: learning rate: None batch_size: 32 epochs: 100 hidden: 80\n",
      "Working on: learning rate: None batch_size: 32 epochs: 100 hidden: 100\n",
      "Working on: learning rate: None batch_size: 32 epochs: 100 hidden: 120\n",
      "Working on: learning rate: None batch_size: 32 epochs: 150 hidden: 80\n",
      "Working on: learning rate: None batch_size: 32 epochs: 150 hidden: 100\n",
      "Working on: learning rate: None batch_size: 32 epochs: 150 hidden: 120\n",
      "Working on: learning rate: None batch_size: 32 epochs: 200 hidden: 80\n",
      "Working on: learning rate: None batch_size: 32 epochs: 200 hidden: 100\n",
      "Working on: learning rate: None batch_size: 32 epochs: 200 hidden: 120\n",
      "Working on: learning rate: None batch_size: 32 epochs: 250 hidden: 80\n",
      "Working on: learning rate: None batch_size: 32 epochs: 250 hidden: 100\n",
      "Working on: learning rate: None batch_size: 32 epochs: 250 hidden: 120\n",
      "Working on: learning rate: None batch_size: 32 epochs: 300 hidden: 80\n",
      "Working on: learning rate: None batch_size: 32 epochs: 300 hidden: 100\n",
      "Working on: learning rate: None batch_size: 32 epochs: 300 hidden: 120\n",
      "Working on: learning rate: None batch_size: 64 epochs: 50 hidden: 80\n",
      "Working on: learning rate: None batch_size: 64 epochs: 50 hidden: 100\n",
      "Working on: learning rate: None batch_size: 64 epochs: 50 hidden: 120\n",
      "Working on: learning rate: None batch_size: 64 epochs: 100 hidden: 80\n",
      "Working on: learning rate: None batch_size: 64 epochs: 100 hidden: 100\n",
      "Working on: learning rate: None batch_size: 64 epochs: 100 hidden: 120\n",
      "Working on: learning rate: None batch_size: 64 epochs: 150 hidden: 80\n",
      "Working on: learning rate: None batch_size: 64 epochs: 150 hidden: 100\n",
      "Working on: learning rate: None batch_size: 64 epochs: 150 hidden: 120\n",
      "Working on: learning rate: None batch_size: 64 epochs: 200 hidden: 80\n",
      "Working on: learning rate: None batch_size: 64 epochs: 200 hidden: 100\n",
      "Working on: learning rate: None batch_size: 64 epochs: 200 hidden: 120\n",
      "Working on: learning rate: None batch_size: 64 epochs: 250 hidden: 80\n",
      "Working on: learning rate: None batch_size: 64 epochs: 250 hidden: 100\n",
      "Working on: learning rate: None batch_size: 64 epochs: 250 hidden: 120\n",
      "Working on: learning rate: None batch_size: 64 epochs: 300 hidden: 80\n",
      "Working on: learning rate: None batch_size: 64 epochs: 300 hidden: 100\n",
      "Working on: learning rate: None batch_size: 64 epochs: 300 hidden: 120\n",
      "Working on: learning rate: None batch_size: 96 epochs: 50 hidden: 80\n",
      "Working on: learning rate: None batch_size: 96 epochs: 50 hidden: 100\n",
      "Working on: learning rate: None batch_size: 96 epochs: 50 hidden: 120\n",
      "Working on: learning rate: None batch_size: 96 epochs: 100 hidden: 80\n",
      "Working on: learning rate: None batch_size: 96 epochs: 100 hidden: 100\n",
      "Working on: learning rate: None batch_size: 96 epochs: 100 hidden: 120\n",
      "Working on: learning rate: None batch_size: 96 epochs: 150 hidden: 80\n",
      "Working on: learning rate: None batch_size: 96 epochs: 150 hidden: 100\n",
      "Working on: learning rate: None batch_size: 96 epochs: 150 hidden: 120\n",
      "Working on: learning rate: None batch_size: 96 epochs: 200 hidden: 80\n",
      "Working on: learning rate: None batch_size: 96 epochs: 200 hidden: 100\n",
      "Working on: learning rate: None batch_size: 96 epochs: 200 hidden: 120\n",
      "Working on: learning rate: None batch_size: 96 epochs: 250 hidden: 80\n",
      "Working on: learning rate: None batch_size: 96 epochs: 250 hidden: 100\n",
      "Working on: learning rate: None batch_size: 96 epochs: 250 hidden: 120\n",
      "Working on: learning rate: None batch_size: 96 epochs: 300 hidden: 80\n",
      "Working on: learning rate: None batch_size: 96 epochs: 300 hidden: 100\n",
      "Working on: learning rate: None batch_size: 96 epochs: 300 hidden: 120\n",
      "Working on: learning rate: None batch_size: 128 epochs: 50 hidden: 80\n",
      "Working on: learning rate: None batch_size: 128 epochs: 50 hidden: 100\n",
      "Working on: learning rate: None batch_size: 128 epochs: 50 hidden: 120\n",
      "Working on: learning rate: None batch_size: 128 epochs: 100 hidden: 80\n",
      "Working on: learning rate: None batch_size: 128 epochs: 100 hidden: 100\n",
      "Working on: learning rate: None batch_size: 128 epochs: 100 hidden: 120\n",
      "Working on: learning rate: None batch_size: 128 epochs: 150 hidden: 80\n",
      "Working on: learning rate: None batch_size: 128 epochs: 150 hidden: 100\n",
      "Working on: learning rate: None batch_size: 128 epochs: 150 hidden: 120\n",
      "Working on: learning rate: None batch_size: 128 epochs: 200 hidden: 80\n",
      "Working on: learning rate: None batch_size: 128 epochs: 200 hidden: 100\n",
      "Working on: learning rate: None batch_size: 128 epochs: 200 hidden: 120\n",
      "Working on: learning rate: None batch_size: 128 epochs: 250 hidden: 80\n",
      "Working on: learning rate: None batch_size: 128 epochs: 250 hidden: 100\n",
      "Working on: learning rate: None batch_size: 128 epochs: 250 hidden: 120\n",
      "Working on: learning rate: None batch_size: 128 epochs: 300 hidden: 80\n",
      "Working on: learning rate: None batch_size: 128 epochs: 300 hidden: 100\n",
      "Working on: learning rate: None batch_size: 128 epochs: 300 hidden: 120\n",
      "Working on: learning rate: None batch_size: 256 epochs: 50 hidden: 80\n",
      "Working on: learning rate: None batch_size: 256 epochs: 50 hidden: 100\n",
      "Working on: learning rate: None batch_size: 256 epochs: 50 hidden: 120\n",
      "Working on: learning rate: None batch_size: 256 epochs: 100 hidden: 80\n",
      "Working on: learning rate: None batch_size: 256 epochs: 100 hidden: 100\n",
      "Working on: learning rate: None batch_size: 256 epochs: 100 hidden: 120\n",
      "Working on: learning rate: None batch_size: 256 epochs: 150 hidden: 80\n",
      "Working on: learning rate: None batch_size: 256 epochs: 150 hidden: 100\n",
      "Working on: learning rate: None batch_size: 256 epochs: 150 hidden: 120\n",
      "Working on: learning rate: None batch_size: 256 epochs: 200 hidden: 80\n",
      "Working on: learning rate: None batch_size: 256 epochs: 200 hidden: 100\n",
      "Working on: learning rate: None batch_size: 256 epochs: 200 hidden: 120\n",
      "Working on: learning rate: None batch_size: 256 epochs: 250 hidden: 80\n",
      "Working on: learning rate: None batch_size: 256 epochs: 250 hidden: 100\n",
      "Working on: learning rate: None batch_size: 256 epochs: 250 hidden: 120\n",
      "Working on: learning rate: None batch_size: 256 epochs: 300 hidden: 80\n",
      "Working on: learning rate: None batch_size: 256 epochs: 300 hidden: 100\n",
      "Working on: learning rate: None batch_size: 256 epochs: 300 hidden: 120\n"
     ]
    }
   ],
   "source": [
    "seed = 387\n",
    "\n",
    "X = np.genfromtxt('data/orth-kid.csv', delimiter=\",\")\n",
    "Y = np.genfromtxt('data/phon-kid.csv', delimiter=\",\")\n",
    "\n",
    "with open('outputs/tune/tune_3.csv', 'w') as f:\n",
    "    f.write(\"{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                            \"hidden_units\",\n",
    "                                            \"learning_rate\",\n",
    "                                             \"batch_size\",\n",
    "                                             \"epochs\",\n",
    "                                             \"loss_train\",\n",
    "                                             \"accuracy_train\",\n",
    "                                             \"mse_train\",\n",
    "                                             \"loss_test\",\n",
    "                                             \"accuracy_test\",\n",
    "                                             \"mse_test\",\n",
    "                                             \"time\"))\n",
    "    for learning_rate in [.01, .025, .05, .075, .1, .15, .2, .25, None]: \n",
    "        for batch_size in [16, 32, 64, 96, 128, 256]:\n",
    "            for epochs in [50, 100, 150, 200, 250, 300]:\n",
    "                for hidden in [80, 100, 120]:\n",
    "                    print(\"Working on:\", \"learning rate:\", learning_rate, \"batch_size:\", batch_size, \"epochs:\", epochs, \"hidden:\", hidden)\n",
    "                    if learning_rate is not None:\n",
    "                        \n",
    "                        initial_learning_rate = learning_rate\n",
    "                        \n",
    "                        lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "                            initial_learning_rate=initial_learning_rate,\n",
    "                            decay_steps=1000,\n",
    "                            decay_rate=0.96,\n",
    "                            staircase=True)  # If True, decay the learning rate at discrete intervals\n",
    "       \n",
    "                        optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "                    if learning_rate is None:\n",
    "                        optimzer = None\n",
    "\n",
    "                    model = learner(X, Y, seed, hidden, optimizer=optimizer)\n",
    "                    \n",
    "                    start_time = time.time()\n",
    "\n",
    "\n",
    "                    model.fit(X, Y, epochs=epochs, batch_size=batch_size, verbose=False)\n",
    "\n",
    "                    end_time = time.time()\n",
    "                    runtime = end_time - start_time\n",
    "\n",
    "                    loss_train, accuracy_train, mse_train = model.evaluate(X, Y, verbose=0) \n",
    "                    loss_test, accuracy_test, mse_test = model.evaluate(X, Y, verbose=0) \n",
    "\n",
    "                    f.write(\"{},{},{},{},{},{},{},{},{},{},{}\\n\".format(\n",
    "                                                    hidden,\n",
    "                                                    learning_rate,\n",
    "                                                    batch_size,\n",
    "                                                    epochs,\n",
    "                                                    loss_train,\n",
    "                                                    accuracy_train,\n",
    "                                                    mse_train,\n",
    "                                                    loss_test,\n",
    "                                                    accuracy_test,\n",
    "                                                    mse_test,\n",
    "                                                    runtime))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python38_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
